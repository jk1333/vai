{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60465319-3670-41c9-8149-746ffad739b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb414bb2-bc7b-4363-8638-7bb54f354d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "PROJECT = \"sandbox-373102\"\n",
    "REGION = \"us-central1\"\n",
    "PACKAGE_PATH = \"package\"\n",
    "ARTIFACT_REGISTRY_ROOT_PATH = \"base\"\n",
    "BASE_CONTAINER = f\"{REGION}-docker.pkg.dev/{PROJECT}/{ARTIFACT_REGISTRY_ROOT_PATH}/transformer:v1\"\n",
    "\n",
    "os.system(f\"mkdir -p {PACKAGE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25470d20-271c-43a4-8764-2896560bb18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.10-slim-buster #nvidia/cuda:12.4.1-runtime-ubuntu22.04 #use for GPU\n",
    "RUN apt-get -y update\n",
    "RUN apt-get -y install python3 python3-pip\n",
    "RUN ln -s /usr/bin/python3 /usr/bin/python\n",
    "RUN pip install scikit-learn==1.3.0 numpy==1.26.0 pandas==2.1.0 joblib==1.3.0\n",
    "ENV VERTEX_CPR_MAX_WORKERS 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306cbe9e-1209-41b5-bb0f-7ae311f7bda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"gcloud builds submit --region={REGION} --tag={BASE_CONTAINER} --machine-type=E2_HIGHCPU_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e27da7a-296a-497d-8bb7-f682e9ba1d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python WARNING: `docker` not in system PATH.\n",
      "`docker` and `docker-credential-gcloud` need to be in the same PATH in order to work correctly together.\n",
      "gcloud's Docker credential helper can be configured but it will not work until this is corrected.\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "Docker configuration file updated.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7a8783-1375-42fc-aa7e-d92343b470a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting below turns all container build and localmodel logs\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6608eae7-f1f4-4f8a-86b1-d6cf9ba4e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing package/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PACKAGE_PATH}/requirements.txt\n",
    "\n",
    "Pillow\n",
    "numpy < 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c074f6-6d14-40ac-af12-495e4a96e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing package/CustomTaxiPredictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PACKAGE_PATH}/CustomTaxiPredictor.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class CustomTaxiPredictor(Predictor):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def load(self, artifacts_uri: str) -> None:\n",
    "        # Load model\n",
    "        logger.info(f\"Starting predictor using {artifacts_uri}\")\n",
    "        origin_path = os.getcwd()\n",
    "        model_path = f\"{origin_path}/model\"\n",
    "        os.makedirs(model_path)\n",
    "        os.chdir(model_path)\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        os.chdir(origin_path)\n",
    "        logger.debug('Start model loading...')\n",
    "        self.model =  joblib.load(f\"{model_path}/model.joblib\")\n",
    "        logger.debug('Model loaded successfully')\n",
    "\n",
    "    def predict(self, prediction_input):\n",
    "        start_time = time.time()\n",
    "        predictions = self.model.predict(prediction_input)\n",
    "        logger.info(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return {\"predictions\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a33f2-ac4e-4b2b-9039-af401a990492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install packages for local testing\n",
    "!pip install scikit-learn==1.3.0 numpy==1.26.0 pandas==2.1.0 joblib==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbfbe0-aaed-46cd-a928-733059f61b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from package.VAIMaskGenerationPredictor import VAIMaskGenerationPredictor\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "#add custom predictor\n",
    "vai_serving_container_uri = f\"{REGION}-docker.pkg.dev/{PROJECT}/custom-inference-gpu/vai-transformer-mask-generator\"\n",
    "\n",
    "#must secure sufficient space\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    src_dir=PACKAGE_PATH,\n",
    "    output_image_uri=vai_serving_container_uri,\n",
    "    predictor=VAIMaskGenerationPredictor,\n",
    "    requirements_path=f\"{PACKAGE_PATH}/requirements.txt\",\n",
    "    #extra_packages=[\"deploy_package/custom_package.tar.gz\"]\n",
    "    base_image=f\"{BASE_CONTAINER}\",\n",
    "    no_cache = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477e3a4-07dc-41c0-9088-0d00d6c1c3f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def openImage(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def image_to_base64(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f83a9-d7a2-4fcf-b8a3-6825a581ab61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_image = openImage(\"car.png\")\n",
    "raw_image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25eaa044-2143-43c1-aac3-d5950b0a55a4",
   "metadata": {},
   "source": [
    "!docker run --gpus all --env AIP_HTTP_PORT=8080 --env AIP_STORAGE_URI=\"gs://jk-model-repo/facebook/sam-vit-large\" asia-northeast1-docker.pkg.dev/sandbox-373102/custom-inference-gpu/vai-transformer-mask-generator -it /bin/bash"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f87ef79-7d4a-4193-baa1-f5f051a3f3b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Simple test using with grammar\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stderr)\n",
    "\n",
    "test_artifact_uri = \"gs://jk-model-repo/facebook/sam-vit-large\"\n",
    "with local_model.deploy_to_local_endpoint(\n",
    "        artifact_uri=test_artifact_uri,\n",
    "        gpu_count=-1\n",
    "    ) as local_endpoint:\n",
    "    health_check_response = local_endpoint.run_health_check()\n",
    "    request = {\n",
    "        \"instances\" : [\n",
    "            {\n",
    "            #\"image\": image_to_base64(raw_image),\n",
    "            \"image_uri\": \"car.png\",\n",
    "            \"input_boxes\": [[650, 900, 1000, 1250], [2050, 800, 2400, 1150]]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request=json.dumps(request),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    print(endpoint.container.logs().decode(\"utf-8\").strip(), sep=\"\\n\")\n",
    "    print(health_check_response, health_check_response.content)\n",
    "    print(predict_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ca109-b325-4ff6-8d53-08940a739aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stderr)\n",
    "\n",
    "test_artifact_uri = \"gs://jk-model-repo/facebook/sam-vit-large\"\n",
    "local_endpoint = local_model.deploy_to_local_endpoint(artifact_uri=test_artifact_uri, gpu_count=-1)\n",
    "local_endpoint.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54d3e0-b910-4142-8d2f-2b26a64c2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "        \"instances\" : [\n",
    "            {\n",
    "            #\"image\": image_to_base64(raw_image),\n",
    "            \"image_uri\": \"car.png\",\n",
    "            \"input_boxes\": [[650, 900, 1000, 1250], [2050, 800, 2400, 1150]]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "predict_response = local_endpoint.predict(\n",
    "        request=json.dumps(request),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "predict_response.json()['predictions'][0]['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00123bac-af06-4729-9a35-7b9648b78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_endpoint.container.logs().decode(\"utf-8\").strip(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5d739-4287-4380-a5a7-2e27155eaf98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#image = torch.zeros(480, 640, 3, dtype=torch.uint8) #black color\n",
    "#image[:, :, :] = 255 #white color\n",
    "import numpy as np\n",
    "base = np.zeros((raw_image.height, raw_image.width, 3), np.uint8) #black color\n",
    "base[:] = (255, 255, 255) #white color\n",
    "for mask in predict_response.json()['predictions'][0]['masks']:\n",
    "    #image = np.array(mask).reshape(height, width, 1)\n",
    "    #np.copyto(base, image, where=(image != 0))\n",
    "    base += np.array(mask).reshape(raw_image.height, raw_image.width, 1)\n",
    "base = 255 - base #inverse color\n",
    "plt.imshow(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63685b2d-71d2-416b-b37e-2e1cb7c3093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116366f-c22f-447c-af5f-206aed2bbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np    \n",
    "\n",
    "output = np.array(raw_image) / 255\n",
    "for mask in predict_response.json()['predictions'][0]['masks']:\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    image = (np.array(mask).reshape(raw_image.height, raw_image.width, 1) * color.reshape(1, 1, -1))[:, :, :3]\n",
    "    np.copyto(output, image, where=(image != 0))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d127a-83ee-4cdf-948a-5fea1d535f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Push locally built image to artifact registry for deploy\n",
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d918272-6d24-4614-9643-f7383c8c297c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make model be used for Model repository\n",
    "from google.cloud import aiplatform\n",
    "model = aiplatform.Model.upload(\n",
    "    location=REGION,\n",
    "    display_name = \"sam_bbox\",\n",
    "    local_model = local_model,\n",
    "    artifact_uri = test_artifact_uri,\n",
    "    #parent_model = prev_model.resource_name,\n",
    "    #is_default_version=True,\n",
    "    serving_container_environment_variables={\n",
    "        # Optional env var so that `uvicorn` only runs the model in 1 worker\n",
    "        \"VERTEX_CPR_MAX_WORKERS\": 4,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d34b3-5d71-429d-87c3-09b49ceb4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create endpoint for model hosting\n",
    "remote_endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=f\"SAM test endpoint\",\n",
    "    #labels={\"sample-key\": \"sample-value\"},\n",
    "    location=REGION,\n",
    "    dedicated_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463985c-1739-4581-94e3-1448dbb3876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy model under the endpoint\n",
    "remote_endpoint.deploy(\n",
    "    model=model,\n",
    "    machine_type=\"g2-standard-4\",\n",
    "    #tpu_topology=None,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    service_account=\"1045259343465-compute@developer.gserviceaccount.com\",\n",
    "    #traffic_percentage=50\n",
    "    #traffic_split={'a':50, 'b':50}\n",
    "    #Configs for GPU\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    accelerator_count=1,\n",
    "    #deploy_request_timeout=DEPLOY_TIMEOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cbced-77ae-4972-8f83-d4e96bafdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\n",
    "    {\n",
    "        #\"image\": image_to_base64(raw_image),\n",
    "        \"image_uri\": \"car.png\",\n",
    "        \"input_boxes\": [[650, 900, 1000, 1250], [2050, 800, 2400, 1150]]\n",
    "    }\n",
    "]\n",
    "predict_response = remote_endpoint.predict(\n",
    "    instances=instances,\n",
    "    use_dedicated_endpoint = True\n",
    ")\n",
    "predict_response.predictions[0]['scores']"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
