{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60465319-3670-41c9-8149-746ffad739b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb414bb2-bc7b-4363-8638-7bb54f354d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = \"YOUR_PROJECT_ID\"\n",
    "REGION = \"us-central1\"\n",
    "PACKAGE_PATH = \"package\"\n",
    "REPO_NAME = \"base\"\n",
    "BASE_CONTAINER = f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPO_NAME}/scikit-learn:v1\"\n",
    "SERVICE_ACCOUNT = \"YOUR_SERVICE_ACCOUNT\"\n",
    "BUCKET_NAME = f\"{PROJECT}-vai\"\n",
    "MODEL_PATH = f\"gs://{BUCKET_NAME}/\"\n",
    "\n",
    "os.system(f\"mkdir -p {PACKAGE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50f690-8d10-481f-98b8-3343f03647f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create base folder udner artifactory registry\n",
    "os.system(f\"gcloud artifacts repositories create {REPO_NAME} --location={REGION} --repository-format=DOCKER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25470d20-271c-43a4-8764-2896560bb18a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.8\n",
    "#FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04 #use for GPU\n",
    "RUN pip install numpy==1.18.5\n",
    "RUN pip install scikit-learn==1.0.2 joblib==0.15.1\n",
    "ENV VERTEX_CPR_MAX_WORKERS 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cbe9e-1209-41b5-bb0f-7ae311f7bda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system(f\"gcloud builds submit --region={REGION} --tag={BASE_CONTAINER}\") #Additionally you can specify build machine type for faster build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27da7a-296a-497d-8bb7-f682e9ba1d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a8783-1375-42fc-aa7e-d92343b470a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting below turns all container build and localmodel logs\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608eae7-f1f4-4f8a-86b1-d6cf9ba4e4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {PACKAGE_PATH}/requirements.txt\n",
    "\n",
    "xgboost==1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c074f6-6d14-40ac-af12-495e4a96e20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {PACKAGE_PATH}/CustomTaxiPredictor.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class CustomTaxiPredictor(Predictor):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def load(self, artifacts_uri: str) -> None:\n",
    "        # Load model\n",
    "        logger.info(f\"Starting predictor using {artifacts_uri}\")\n",
    "        origin_path = os.getcwd()\n",
    "        model_path = f\"{origin_path}/model\"\n",
    "        os.makedirs(model_path)\n",
    "        os.chdir(model_path)\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        os.chdir(origin_path)\n",
    "        logger.debug('Start model loading...')\n",
    "        self.model =  joblib.load(f\"{model_path}/model.joblib\")\n",
    "        logger.debug('Model loaded successfully')\n",
    "\n",
    "    def predict(self, prediction_input):\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"--- input: {prediction_input['instances']}\")\n",
    "        try:\n",
    "            predictions = self.model.predict(prediction_input[\"instances\"])\n",
    "        except Exception as e:\n",
    "            logger.info(e)\n",
    "        logger.info(f\"--- Result: {predictions}\")\n",
    "        logger.info(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return {\"predictions\": list(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbfbe0-aaed-46cd-a928-733059f61b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from package.CustomTaxiPredictor import CustomTaxiPredictor\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "#add custom predictor\n",
    "vai_serving_container_uri = f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPO_NAME}/customtaxipredictor\" #Must be lower case\n",
    "\n",
    "#must secure sufficient space\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    src_dir=PACKAGE_PATH,\n",
    "    output_image_uri=vai_serving_container_uri,\n",
    "    predictor=CustomTaxiPredictor,\n",
    "    requirements_path=f\"{PACKAGE_PATH}/requirements.txt\",\n",
    "    #extra_packages=[\"deploy_package/custom_package.tar.gz\"]\n",
    "    base_image=f\"{BASE_CONTAINER}\",\n",
    "    no_cache = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ca109-b325-4ff6-8d53-08940a739aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stderr)\n",
    "\n",
    "local_endpoint = local_model.deploy_to_local_endpoint(artifact_uri=MODEL_PATH, gpu_count=0) #Set -1 if using GPU\n",
    "try:\n",
    "    local_endpoint.serve()\n",
    "    print(local_endpoint.container.logs().decode(\"utf-8\").strip(), sep=\"\\n\")\n",
    "except:\n",
    "    #Run below if need to get container log\n",
    "    print(local_endpoint.container.logs().decode(\"utf-8\").strip(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54d3e0-b910-4142-8d2f-2b26a64c2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "        \"instances\" : [\n",
    "            [485,1.12,0.0,\"Chicago  Carriage  Cab  Corp\",\n",
    "             41.881,-87.633,41.885,-87.643,0,2019,4,1,1,\"Mon\",1.094445752708995]\n",
    "        ]\n",
    "    }\n",
    "predict_response = local_endpoint.predict(\n",
    "        request=json.dumps(request),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "predict_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00123bac-af06-4729-9a35-7b9648b78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_endpoint.container.logs().decode(\"utf-8\").strip(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63685b2d-71d2-416b-b37e-2e1cb7c3093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d127a-83ee-4cdf-948a-5fea1d535f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Push locally built image to artifact registry for deploy\n",
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d918272-6d24-4614-9643-f7383c8c297c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make model be used for Model repository\n",
    "from google.cloud import aiplatform\n",
    "model = aiplatform.Model.upload(\n",
    "    location=REGION,\n",
    "    display_name = \"CustomTaxiPredictor\",\n",
    "    local_model = local_model,\n",
    "    artifact_uri = MODEL_PATH,\n",
    "    #parent_model = prev_model.resource_name,\n",
    "    #is_default_version=True,\n",
    "    serving_container_environment_variables={\n",
    "        # Optional env var so that `uvicorn` only runs the model in 1 worker\n",
    "        \"VERTEX_CPR_MAX_WORKERS\": 4,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d34b3-5d71-429d-87c3-09b49ceb4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create endpoint for model hosting\n",
    "remote_endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=f\"CustomTaxiPredictor test endpoint\",\n",
    "    #labels={\"sample-key\": \"sample-value\"},\n",
    "    location=REGION,\n",
    "    dedicated_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463985c-1739-4581-94e3-1448dbb3876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy model under the endpoint\n",
    "remote_endpoint.deploy(\n",
    "    model=model,\n",
    "    machine_type=\"g2-standard-4\",\n",
    "    #tpu_topology=None,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    #traffic_percentage=50\n",
    "    #traffic_split={'a':50, 'b':50}\n",
    "    #Configs for GPU\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    accelerator_count=1,\n",
    "    #deploy_request_timeout=DEPLOY_TIMEOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cbced-77ae-4972-8f83-d4e96bafdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\n",
    "    [485,1.12,0.0,\"Chicago  Carriage  Cab  Corp\",\n",
    "             41.881,-87.633,41.885,-87.643,0,2019,4,1,1,\"Mon\",1.094445752708995]\n",
    "]\n",
    "predict_response = remote_endpoint.predict(\n",
    "    instances=instances,\n",
    "    use_dedicated_endpoint = True\n",
    ")\n",
    "predict_response.predictions"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
